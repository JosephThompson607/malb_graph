{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-GuEutjJAl67JmbN7TIGv97nKm8Vzwtq",
      "authorship_tag": "ABX9TyPB672pMGcBhmuqaVboBpu9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosephThompson607/malb_graph/blob/main/classifying_SALB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoJSmOgtN5ql",
        "outputId": "8bda9bcf-e485-4afa-f1b6-75bedcca7fed"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: #adds /content/drive/MyDrive/ALB_stuff/python/ALB_instance_tools.py\n",
        "\n",
        "# Add the specified file to the current path, assuming it exists.\n",
        "import sys\n",
        "import os.path as osp\n",
        "import os\n",
        "import glob\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/ALB_stuff/python/')\n",
        "from ALB_instance_tools import *\n",
        "from ALB_station_fill_heuristic import *\n",
        "from classification_generation import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "# Install torch_geometric if not already installed\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ImportError:\n",
        "    !pip install torch-geometric\n",
        "\n",
        "from torch_geometric.data import Dataset, Data, InMemoryDataset\n"
      ],
      "metadata": {
        "id": "SVyzCp9Uu0nw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT1eiq3-ui19",
        "outputId": "0ac6f932-d274-45a7-dfb7-a430cb4eac5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             instance_name  positional_weight  reverse_positional_weight  \\\n",
            "0    instance_n=20_500.alb                  7                          7   \n",
            "1    instance_n=20_107.alb                 13                         13   \n",
            "2    instance_n=20_421.alb                  5                          5   \n",
            "3     instance_n=20_45.alb                  5                          5   \n",
            "4    instance_n=20_193.alb                  4                          4   \n",
            "..                     ...                ...                        ...   \n",
            "520  instance_n=20_517.alb                  3                          2   \n",
            "521  instance_n=20_524.alb                  2                          2   \n",
            "522  instance_n=20_525.alb                  2                          2   \n",
            "523  instance_n=20_519.alb                  2                          2   \n",
            "524  instance_n=20_516.alb                  2                          2   \n",
            "\n",
            "     n_followers  n_predecessors  n_immediate_followers  work_element_time  \\\n",
            "0              7               7                      7                  7   \n",
            "1             13              13                     13                 13   \n",
            "2              5               5                      5                  5   \n",
            "3              5               5                      5                  5   \n",
            "4              4               4                      4                  4   \n",
            "..           ...             ...                    ...                ...   \n",
            "520            3               2                      3                  2   \n",
            "521            2               3                      2                  2   \n",
            "522            2               2                      2                  2   \n",
            "523            3               3                      3                  2   \n",
            "524            2               2                      2                  2   \n",
            "\n",
            "     random_weight  best  worst  \n",
            "0                7     7      7  \n",
            "1               13    13     13  \n",
            "2                5     5      5  \n",
            "3                5     5      5  \n",
            "4                5     4      5  \n",
            "..             ...   ...    ...  \n",
            "520              3     2      3  \n",
            "521              2     2      3  \n",
            "522              2     2      2  \n",
            "523              3     2      3  \n",
            "524              2     2      2  \n",
            "\n",
            "[525 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "instance_list = get_instance_list(\"/content/drive/MyDrive/ALB_stuff/pytorch_datasets/raw/small data set_n=20\")\n",
        "comp_df = generate_heuristic_comparison(instance_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_alb = SALBP_Instance(instance_list[0], instance_list[0])\n",
        "tasks = test_alb.task_times.copy()\n",
        "#orders tasks by task number (turns string to int), returns task times (value of dict)\n",
        "tasks = dict(sorted(tasks.items(), key=lambda item: int(item[0])))\n",
        "print\n",
        "task_times = list(tasks.values())\n",
        "task_times\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjgWjkAGIdx0",
        "outputId": "fe027932-a467-48a7-8f1b-1401fac208c9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[238,\n",
              " 508,\n",
              " 501,\n",
              " 511,\n",
              " 469,\n",
              " 53,\n",
              " 256,\n",
              " 445,\n",
              " 132,\n",
              " 100,\n",
              " 271,\n",
              " 445,\n",
              " 52,\n",
              " 162,\n",
              " 555,\n",
              " 195,\n",
              " 563,\n",
              " 60,\n",
              " 235,\n",
              " 485]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class SALBDataset(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None,raw_data_folder = \"raw/small data set_n=20\", alb_filepath=None):\n",
        "        self.raw_data_folder = raw_data_folder\n",
        "        self.alb_files = get_instance_list(alb_filepath, keep_directory_location=False)\n",
        "        self.instance_length = len(self.alb_files)\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_dir(self):\n",
        "        # Define your custom raw directory\n",
        "        return osp.join(self.root, self.raw_data_folder)\n",
        "    @property\n",
        "    def processed_dir(self):\n",
        "        # Define your custom processed directory\n",
        "        return osp.join(self.root, 'processed/')\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        # List files in `raw_dir` necessary for generating the dataset.\n",
        "        return self.alb_files\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        # List files in `processed_dir` that are already processed.\n",
        "        return [f\"instance_n=20_{idx}.pt\" for idx in range(self.instance_length)]\n",
        "\n",
        "    def download(self):\n",
        "        # Logic for downloading raw data if it does not exist.\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        # Read raw data and save processed data to `processed_dir`.\n",
        "        for idx,raw_path in enumerate(self.raw_paths):\n",
        "            print(f\"Processing {raw_path}...\")\n",
        "           #self.name = raw_path.split(\"/\")[-1].split(\".\")[0]\n",
        "            # Example: Read graph data\n",
        "            salb_inst = SALBP_Instance(\"test\",raw_path)\n",
        "            edge_index = torch.tensor(salb_inst.get_python_edge_list(), dtype=torch.long)\n",
        "            x = torch.tensor([salb_inst.get_task_times_list()], dtype=torch.float)\n",
        "            #y = torch.tensor([0], dtype=torch.long)\n",
        "\n",
        "            data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
        "            torch.save(data, self.processed_dir +\"instance_n=20_\" + str(idx) + \".pt\")\n",
        "\n",
        "    def len(self):\n",
        "        # Return the number of graphs in the dataset.\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        # Load and return a graph object by index.\n",
        "        data = torch.load(f\"{self.processed_dir}/instance_n=20_{idx}.pt\")\n",
        "        return data\n",
        "\n",
        "\n",
        "my_dataset = SALBDataset(root='/content/drive/MyDrive/ALB_stuff/pytorch_datasets', alb_filepath=\"/content/drive/MyDrive/ALB_stuff/pytorch_datasets/raw/small data set_n=20\")"
      ],
      "metadata": {
        "id": "X-xyIEWtva8_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTj7t55hWT9N",
        "outputId": "c1a65f26-b9e7-46ab-c5a2-fb6164f33ce4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-fe28cab59b57>:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(f\"{self.processed_dir}/instance_n=20_{idx}.pt\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[1, 20, 1], edge_index=[2, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: deletes all .pt files in /content/drive/MyDrive/ALB_stuff/pytorch_datasets/\n",
        "\n",
        "\n",
        "# def delete_pt_files(directory):\n",
        "#   \"\"\"Deletes all .pt files in the specified directory.\n",
        "#   \"\"\"\n",
        "#   for filename in glob.glob(os.path.join(directory, \"*.pt\")):\n",
        "#     try:\n",
        "#       os.remove(filename)\n",
        "#       print(f\"Deleted: {filename}\")\n",
        "#     except OSError as e:\n",
        "#       print(f\"Error deleting {filename}: {e}\")\n",
        "\n",
        "# # Example usage:\n",
        "# directory_to_clean = \"/content/drive/MyDrive/ALB_stuff/pytorch_datasets/processed\"\n",
        "# delete_pt_files(directory_to_clean)"
      ],
      "metadata": {
        "id": "DM5jSjFrvOpf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}